{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select() Function\n",
    "It is a transformation function used to return the new Dataframe\n",
    "\n",
    "1. It return only the selected columns\n",
    "2. Can specify multiple columns\n",
    "3. Select specifies columns and/or rename\n",
    "\n",
    "what is the difference in withColumn() ?\n",
    "1. used for add / modify columns\n",
    "2. Return all columns\n",
    "3. Can add only 1 column at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating spark session and df\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"learning\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "data = [(\"James\",\"Smith\",\"USA\",\"CA\"),\n",
    "    (\"Michael\",\"Rose\",\"USA\",\"NY\"),\n",
    "    (\"Robert\",\"Williams\",\"USA\",\"CA\"),\n",
    "    (\"Maria\",\"Jones\",\"USA\",\"FL\")\n",
    "  ]\n",
    "# Column names\n",
    "columns = [\"firstname\",\"lastname\",\"country\",\"state\"]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data = data, schema = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+-----+\n",
      "|firstname|lastname|country|state|\n",
      "+---------+--------+-------+-----+\n",
      "|James    |Smith   |USA    |CA   |\n",
      "|Michael  |Rose    |USA    |NY   |\n",
      "|Robert   |Williams|USA    |CA   |\n",
      "|Maria    |Jones   |USA    |FL   |\n",
      "+---------+--------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|firstname|\n",
      "+---------+\n",
      "|    James|\n",
      "|  Michael|\n",
      "|   Robert|\n",
      "|    Maria|\n",
      "+---------+\n",
      "\n",
      "+---------+--------+\n",
      "|firstname|lastname|\n",
      "+---------+--------+\n",
      "|    James|   Smith|\n",
      "|  Michael|    Rose|\n",
      "|   Robert|Williams|\n",
      "|    Maria|   Jones|\n",
      "+---------+--------+\n",
      "\n",
      "+---------+\n",
      "|firstname|\n",
      "+---------+\n",
      "|    James|\n",
      "|  Michael|\n",
      "|   Robert|\n",
      "|    Maria|\n",
      "+---------+\n",
      "\n",
      "+---------+\n",
      "|firstname|\n",
      "+---------+\n",
      "|    James|\n",
      "|  Michael|\n",
      "|   Robert|\n",
      "|    Maria|\n",
      "+---------+\n",
      "\n",
      "+---------+--------+\n",
      "|firstname|lastname|\n",
      "+---------+--------+\n",
      "|    James|   Smith|\n",
      "|  Michael|    Rose|\n",
      "|   Robert|Williams|\n",
      "|    Maria|   Jones|\n",
      "+---------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# list of ways to select columns list of columns\n",
    "\n",
    "df.select(\"firstname\").show()\n",
    "df.select(df.firstname,df.lastname).show()\n",
    "df.select(df[\"firstname\"]).show()\n",
    "\n",
    "# using col function\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "df.select(col(\"firstname\")).show()\n",
    "\n",
    "#using regex function\n",
    "df.select(df.colRegex(\"`^.*name*`\")).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+-----+\n",
      "|firstname|lastname|country|state|\n",
      "+---------+--------+-------+-----+\n",
      "|    James|   Smith|    USA|   CA|\n",
      "|  Michael|    Rose|    USA|   NY|\n",
      "|   Robert|Williams|    USA|   CA|\n",
      "|    Maria|   Jones|    USA|   FL|\n",
      "+---------+--------+-------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+-----+\n",
      "|firstname|lastname|country|state|\n",
      "+---------+--------+-------+-----+\n",
      "|    James|   Smith|    USA|   CA|\n",
      "|  Michael|    Rose|    USA|   NY|\n",
      "|   Robert|Williams|    USA|   CA|\n",
      "|    Maria|   Jones|    USA|   FL|\n",
      "+---------+--------+-------+-----+\n",
      "\n",
      "+---------+--------+-------+-----+\n",
      "|firstname|lastname|country|state|\n",
      "+---------+--------+-------+-----+\n",
      "|    James|   Smith|    USA|   CA|\n",
      "|  Michael|    Rose|    USA|   NY|\n",
      "|   Robert|Williams|    USA|   CA|\n",
      "|    Maria|   Jones|    USA|   FL|\n",
      "+---------+--------+-------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# selecting all columns\n",
    "\n",
    "df.select(*columns).show()\n",
    "df.select(\"*\").show()\n",
    "df.select([col for col in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+-----+\n",
      "|firstname|lastname|country|state|\n",
      "+---------+--------+-------+-----+\n",
      "|    James|   Smith|    USA|   CA|\n",
      "|  Michael|    Rose|    USA|   NY|\n",
      "|   Robert|Williams|    USA|   CA|\n",
      "|    Maria|   Jones|    USA|   FL|\n",
      "+---------+--------+-------+-----+\n",
      "\n",
      "+-------+-----+\n",
      "|country|state|\n",
      "+-------+-----+\n",
      "|    USA|   CA|\n",
      "|    USA|   NY|\n",
      "|    USA|   CA|\n",
      "|    USA|   FL|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# selecting columns based on index\n",
    "df.select(df.columns).show()\n",
    "df.select(df.columns[2:]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------+------+\n",
      "|              name|location|Salary|\n",
      "+------------------+--------+------+\n",
      "|{padmanabhan, , s}| chennai|  5000|\n",
      "|  {Deva, kumar, k}|  trichy|  1000|\n",
      "+------------------+--------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# select in complex nested columns\n",
    "from pyspark.sql.types import StructType,StructField,StringType,IntegerType\n",
    "\n",
    "comp_data = [((\"padmanabhan\",\"\",\"s\"),\"chennai\",5000),\n",
    "             ((\"Deva\",\"kumar\",\"k\"),\"trichy\",1000)]\n",
    "\n",
    "schema = StructType([StructField(\"name\",StructType([\n",
    "                                        StructField(\"firstName\",StringType(),False),\n",
    "                                        StructField(\"middleName\",StringType(),False),\n",
    "                                        StructField(\"lastName\",StringType(),False)])),\n",
    "                     StructField(\"location\",StringType(),True),\n",
    "                     StructField(\"Salary\",IntegerType(),False)\n",
    "                    ])\n",
    "\n",
    "df = spark.createDataFrame(comp_data,schema=schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|  firstName|\n",
      "+-----------+\n",
      "|padmanabhan|\n",
      "|       Deva|\n",
      "+-----------+\n",
      "\n",
      "+-----------+----------+--------+\n",
      "|  firstName|middleName|lastName|\n",
      "+-----------+----------+--------+\n",
      "|padmanabhan|          |       s|\n",
      "|       Deva|     kumar|       k|\n",
      "+-----------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"name.firstName\").show()\n",
    "df.select(\"name.*\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigdataEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
